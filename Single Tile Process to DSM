import arcpy
import requests
import os
import time

def check_path_accessible(path):
    """Check if a path is accessible."""
    if not os.path.exists(path):
        raise FileNotFoundError(f"The path {path} does not exist.")
    if not os.access(path, os.R_OK):
        raise PermissionError(f"The path {path} is not readable.")
    print(f"The path {path} is accessible and readable.")

def display_error_message(url, feature_id, error):
    """Display an error message with the URL and feature ID causing the issue."""
    print(f"Error downloading {url} for feature ID {feature_id}: {error}")

def get_selected_feature_count(layer):
    """Get the count of selected features."""
    selected_count = int(arcpy.GetCount_management(layer).getOutput(0))
    return selected_count

def check_field_exists(layer, field_name):
    """Check if a field exists in the layer."""
    field_names = [field.name for field in arcpy.ListFields(layer)]
    if field_name not in field_names:
        raise ValueError(f"The field '{field_name}' does not exist in the feature layer.")
    print(f"The field '{field_name}' exists in the feature layer.")

def extract_url_from_html(anchor_tag):
    """Extract the URL from an HTML anchor tag."""
    try:
        return anchor_tag.split('"')[1].strip()
    except IndexError:
        return None

def download_file(url, file_path, retries=3):
    """Download a file from a URL with retry logic."""
    for attempt in range(retries):
        try:
            response = requests.get(url)
            response.raise_for_status()
            with open(file_path, 'wb') as file:
                file.write(response.content)
            return True
        except requests.exceptions.RequestException as e:
            if attempt < retries - 1:
                print(f"Retrying... (Attempt {attempt + 2})")
            else:
                print(f"Failed to download {url}: {e}")
    return False

def process_tile(feature_id, url, base_download_directory):
    """
    Process a single tile:
      - Create a dedicated folder for the tile.
      - Download the file from the URL.
      - If the file is a LAZ file, convert it to LAS.
      - For each LAS file produced, convert it individually to a DSM raster.
    """
    # Create a unique folder for this tile (using the feature's OID)
    tile_folder = os.path.join(base_download_directory, f"tile_{feature_id}")
    laz_directory = os.path.join(tile_folder, 'LAZ')
    las_directory = os.path.join(tile_folder, 'LAS')
    dsm_directory = os.path.join(tile_folder, 'DSM')
    
    # Create directories if they don't exist
    for directory in [tile_folder, laz_directory, las_directory, dsm_directory]:
        if not os.path.exists(directory):
            os.makedirs(directory)
    
    print(f"Processing feature {feature_id}...")
    
    # Clean and extract the URL if needed
    url = url.strip()
    if '<a href="' in url:
        url = extract_url_from_html(url)
    
    # Get the filename from the URL (assumes the URL ends with the filename)
    filename = os.path.basename(url)
    # Determine download destination based on file extension
    if filename.lower().endswith('.laz'):
        file_path = os.path.join(laz_directory, filename)
    else:
        file_path = os.path.join(las_directory, filename)
    
    # Attempt to download the file
    if not download_file(url, file_path):
        display_error_message(url, feature_id, "Failed after multiple attempts")
        return False
    print(f"Downloaded {file_path} for feature {feature_id}")
    
    # If the file is LAZ, convert it to LAS and output to the LAS directory
    if file_path.lower().endswith('.laz'):
        try:
            arcpy.conversion.ConvertLas(file_path, las_directory)
            print(f"Converted {file_path} to LAS files in {las_directory}")
        except Exception as e:
            print(f"Error converting {file_path} to LAS for feature {feature_id}: {e}")
            return False
        # Pause briefly to allow file system updates
        time.sleep(2)
    
    # Process each LAS file individually (since the tool does not accept multiple LAS files)
    las_files = [os.path.join(las_directory, f) for f in os.listdir(las_directory) if f.lower().endswith('.las')]
    if not las_files:
        print(f"No LAS files found for feature {feature_id}.")
        return False
    
    for las_file in las_files:
        # Define DSM output path (use the LAS filename with a _DSM.tif suffix)
        base_name = os.path.splitext(os.path.basename(las_file))[0]
        dsm_output = os.path.join(dsm_directory, f"{base_name}_DSM.tif")
        try:
            arcpy.conversion.LasDatasetToRaster(
                in_las_dataset=las_file,  # process one LAS file at a time
                out_raster=dsm_output,
                value_field="ELEVATION",
                interpolation_type="BINNING MAXIMUM NATURAL_NEIGHBOR",
                data_type="FLOAT",
                sampling_type="CELLSIZE",
                sampling_value=2,  # adjust cell size if necessary
                z_factor=1         # keep elevation scale unchanged
            )
            print(f"Created DSM raster {dsm_output} for LAS file {las_file}")
        except Exception as e:
            print(f"Error creating DSM for LAS file {las_file} for feature {feature_id}: {e}")
    
    return True

def process_all_tiles(feature_layer, base_download_directory, link_field):
    """
    Iterate through each selected feature in the feature layer,
    processing each tile one at a time.
    """
    # Ensure the link field exists
    check_field_exists(feature_layer, link_field)
    
    # Get the count of selected features
    selected_count = get_selected_feature_count(feature_layer)
    if selected_count == 0:
        print("No features selected.")
        return
    else:
        print(f"{selected_count} features selected. Processing starting.")
    
    total_files = 0
    successful = 0
    
    # Iterate through each selected feature that has a non-null link field
    with arcpy.da.SearchCursor(feature_layer, ["OID@", link_field],
                               where_clause="{} IS NOT NULL".format(arcpy.AddFieldDelimiters(feature_layer, link_field))) as cursor:
        for row in cursor:
            total_files += 1
            feature_id, url = row[0], row[1]
            print(f"\n--- Processing feature {feature_id} ---")
            if process_tile(feature_id, url, base_download_directory):
                successful += 1
    
    print(f"\nProcessing completed. {successful}/{total_files} features processed successfully.")

# Main script
if __name__ == "__main__":
    # Feature layer (as it appears in the ArcGIS project)
    feature_layer = "va2018_fairfax_index"  # Replace with your feature layer name
    # Base download directory (this is where per-tile folders will be created)
    base_download_directory = r"D:\Fairfax County\NVRC_DM_Grid20"  # Replace with your download directory path
    # Link field containing the URL (must match the field name in the feature layer)
    link_field = "URL"  # Replace with the attribute field name (not alias) containing the URL
    
    process_all_tiles(feature_layer, base_download_directory, link_field)
